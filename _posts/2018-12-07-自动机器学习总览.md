---
layout:     post
title:      自动机器学习总览
subtitle:   A Survey on Automated Machine Learning
date:       2018-12-07
author:     Jiayue Cai
header-img: img/post-bg-ai.jpg
catalog: true
tags:
    - Machine Learning
    - Automated Machine Learning
---


> Last updated on 2020-6-19...

- [元学习博客链接](https://coladrill.github.io/2018/10/24/%E5%85%83%E5%AD%A6%E4%B9%A0%E6%80%BB%E8%A7%88/)
- [强化学习博客链接](https://coladrill.github.io/2018/12/02/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E6%80%BB%E8%A7%88/)
- [深度强化学习博客链接](https://coladrill.github.io/2018/10/21/%E6%B7%B1%E5%BA%A6%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E7%BB%BC%E8%BF%B0/)

![](/img/post/20181207/0.png)

AutoML论文整理：[链接](https://github.com/hibayesian/awesome-automl-papers)。

本文综述方面的内容绝大部分来自于2018年末的论文[《Taking Human out of Learning Applications: A Survey on Automated Machine Learning》](https://arxiv.org/pdf/1810.13306.pdf)，文中的引用序号可参见原文的引用来查找论文。

目前2020年初最新的综述为：[《AutoML: A Survey of the State-of-the-Art》](https://arxiv.org/abs/1908.00709)。

### 引言

机器学习技术深深植根于我们的日常生活中。然而，由于追求良好的学习成绩是知识和劳动密集型的，因此人类专家大量参与机器学习的各个方面。为了使机器学习技术更容易应用并减少对经验丰富的人类专家的需求，自动机器学习（AutoML）已成为工业和学术界的热门话题。

### AutoML定义

AutoML不仅希望具有良好的学习性能（从机器学习的角度来看），而且还要求在没有人工协助的情况下实现这种性能（从自动化的角度来看）。 因此，AutoML的非正式和直观描述可以表示为
![](/img/post/20181207/1.png)

> `定义1 机器学习`：计算机程序先从某些类别的`任务T`和`性能测量P`中`经验E`中学习，如果其性能可以通过P测量的E在T上得到改善。

> `定义2 AutoML `: AutoML尝试构建机器学习程序（由定义1中的E，T和P指定），无需人工协助且在有限的计算预算内。

为了更好地理解定义2，表1中举出了三个例子：
![](/img/post/20181207/2.png)

- `自动模型选择`：这里，**E表示输入训练数据，T表示分类任务，P表示给定任务的准确性**。当给出特征时，Auto-sklearn可以选择合适的分类器并在没有人工帮助的情况下找到相应的超参数。
- `神经结构搜索`：当我们尝试在NAS的帮助下进行一些图像分类问题时，**E是图像的集合，T是图像分类问题，P是测试图像的准确性**。 NAS将自动搜索神经架构，即基于神经网络的分类器，其在给定任务上具有良好性能。
- `自动特征工程`：由于输入特征可能不够丰富，我们可能需要构建更多特征以提高学习效果。在这种情况下，**E是原始特征，T是特征的构造，P是用构造的特征学习的模型的性能**。 [DSM](https://ieeexplore.ieee.org/document/7344858)和[ExploreKit](https://people.eecs.berkeley.edu/~dawnsong/papers/icdm-2016.pdf)通过基于输入要素之间的交互自动构建新要素来消除人工辅助。

最后，请注意，定义2足以涵盖大多数可被视为自动的机器学习方法。 根据这个定义，具有固定配置的机器学习管道也不会根据不同的E，T和P进行调整，这也是自动的。 

**AutoML目标：**
- 更好的性能：在各种输入数据和学习任务中具有良好的泛化性能;
- 没有人类的帮助：可以自动完成机器学习工具的配置; 
- 较低的计算预算：该计划可以在有限的预算内返回产出。

### AutoML框架

在表2中，我们使用表1中的示例来演示`拟议框架`如何涵盖现有工作：
![](/img/post/20181207/3.png)

#### AutoML控制器

![](/img/post/20181207/4.png)

**1、`评估器`：使用优化程序提供的配置来衡量学习工具的性能，生成优化程序的反馈**
- 通常，为了使用给定配置测量学习工具的性能，评估器需要根据输入数据训练模型，这可能非常耗时。
- 然而，评估器还可以基于模仿人类经验的外部知识直接估计绩效。 这种估计非常快，但可能不准确。 
- 因此，对于评估器来说，它需要快速但准确地测量学习工具的性能。

**2、`优化器`：更新或生成学习工具的配置** 
- 优化器的搜索空间由学习工具定义，并且新配置预期比以前的配置具有更好的性能。
- 但是，评估器提供的反馈不必由优化器使用。 这取决于我们正在使用哪种类型的优化算法。 
- 最后，当优化器在搜索空间上运行时，我们希望搜索空间可以轻松紧凑，以便优化器可以通过一些生成的配置识别出良好的配置。

> 优化器专注于搜索和优化配置，可以使用许多方法，从`网格搜索`和`随机搜索`等简单方法到非常复杂的方法，如`强化学习`和`自动差异化（automatic differentiation）`。 

> 然而，对于主要通过确定其参数来测量具有当前配置的学习工具的性能的评估器，可以采用很多方法作为基本方法。

#### 现有方法分类

表3. 通过问题设置对现有AutoML方法进行分类。
![](/img/post/20181207/5.png)

#### Part1 特征工程

在许多情况下，来自数据的`原始特征`可能不够好，例如，它们的维度可能太高或者样本在特征空间中可能不可辨别。 因此，我们可能希望对这些特征进行一些后处理。 

特征工程进一步分为两个子问题：`从数据创建特征`、`增强特征的辨别能力`。**在这里，我们专注于特征增强方法。**

**1、降维**：通过获取一组主要变量来减少所考虑的随机变量数量的过程。

这在特征之间存在大量冗余或特征维度过高时非常有用。它可以分为特征选择和特征投影。 
- 特征选择：试图从原始特征选择特征的子集，流行的方法是贪婪搜索和套索。
- 特征投影：将原始特征转换为新的空间，其尺寸要小得多，例如PCA，LDA和最近的自动编码器。

**2、特征编码**：根据从数据中学习的一些字典重新解释原始特征。 

在编码之后，样本通常在另一个特征空间中被提升，这比原始特征空间高得多。 由于字典可以捕获训练数据中的协作表示，因此在原始空间中不可辨别的样本在新空间中变得可分离。
- 稀疏编码方法[68]：卷积变体[69]、局部线性编码[70]。
- 内核方法：也可以看作特征编码，其中基函数是字典。 但是，内核方法必须与SVM一起使用，基本函数是手工设计的，不是由数据驱动的。

**3、特征生成**：基于一些预定义的操作[ref]来构造来自原始特征的新特征。

由于原始特征是由人类设计的，因此它们之间通常存在未经探索的相互作用，这可以显着提高学习成绩。
- 两个特征的乘法和标准归一化。 
- 它通常被建模为原始特征操作所跨越的空间中的搜索问题。 已经应用了许多搜索算法，例如贪婪搜索[9]和进化算法[45]，[67]。

**上述操作会产生两类搜索空间，对应两种配置（configuration）**：
- 第一类由这些工具的超参数组成，配置正是指这些超参数。
	- 它包括降维和特征编码方法，（例如[5]，[6]，[34]）。 例如，我们需要确定PCA之后的特征维度，以及稀疏编码的稀疏程度。
- 第二类搜索空间来自特征生成（例如[9]，[10]，[45]，[46]，[47]）。 通过预定义操作与原始特征的组合来跨越空间。 
	- plus，minus和times操作生成的新特征的一个示例。对于这些方法，配置是搜索空间中特征的选择。

#### Part2 模型选择

在文献中已经提出了许多分类工具，例如`线性分类器`，`树分类器`，`内核机器`以及最近的`深度网络`。**每个分类器在数据下的建模中都有自己的优势和劣势。**例如，树分类器通常优于线性分类器。 然而，当特征维度变高时，它变得非常昂贵并且难以训练树分类器。

传统上，不同分类器之间的选择通常由人类根据他的经验以反复试验的方式进行。从表4中可以看出，每个分类器还有与其相关联的超参数。
![](/img/post/20181207/6.png)

模型选择同样分为两个子问题：`自动选择分类器`、`设置其超参数`。

从上面，我们可以看到在模型选择的上下文中的配置是分类器及其超参数的选择（例如[5]，[34]，[37]，[48]，[49]）。 这两部分构成了搜索空间。 
- 分类器的选择可以简单地建模为离散变量，1表示使用分类器，0表示不使用。 
- 超参数的属性取决于模型的设计和实现。例如，最近邻居的数量是离散的，而逻辑回归的惩罚参数是连续的。

#### Part3 算法选择

机器学习的最后和最耗时的步骤是找到学习工具的参数，通常涉及优化工具。 在过渡方面，由于优化工具通常非常简单，优化不是一个问题，从各种优化工具获得的性能几乎相同。**效率是选择优化工具的主要焦点。**

表5总结了一些用于`最小化平滑目标函数`的`常用工具`，如`逻辑回归`。
![](/img/post/20181207/7.png)
- 虽然`GD`不涉及任何额外参数，但它的收敛速度慢且每次迭代复杂度很高。 
- `L-BFGS`更昂贵但收敛速度更快。
- 每次迭代在`SGD`中都非常便宜，但在收敛之前需要进行多次迭代。

传统上，优化工具的选择及其超参数都是由人类完成的。这些再次基于人类对学习工具的理解和对训练数据的观察。 

搜索空间由优化工具的配置决定，优化工具包含优化工具的选择及其超参数的值（例如[38]，[50]，[51]，[52]，[53]）。

#### Part4 全范围

其实`搜索`可以通过两种方式完成:
- 分别重复使用`每个`设置的方法然后将它们`组合`在一起。（即`分层结构`，例如[5]，[6]，[21]，[34]）
- `直接`搜索所有配置所跨越的空间。 （`NAS`）

> `网络架构搜索（NAS）`，其目标是搜索深层网络的良好架构（例如[7]，[20]，[40]，[54]，[55]，[56]，[ 57]，[58]，[59]，[60]，[61]，[62]，[72]）。

在描述NAS的搜索空间之前，让我们回顾一下典型的CNN架构：
![](/img/post/20181207/8.png)

深层网络的模型复杂性也可以用于搜索，即我们可以`再添加一层或跳转连接层之间的关系`。这种关键差异是在NAS中使用强化学习[19]的动机。 
因此，搜索空间由上述设计选择和SGD中的超参数组成。 这里针对NAS的一种配置是这种搜索空间中的一个点。
![](/img/post/20181207/9.png)

> 这里提出的想法可以类似地应用于其他深层架构，如长期短期记忆（LSTM）[75]和深度稀疏网络[76]。

> 在NAS中，由于一些设计选择是离散的而不是差分的，因此在[41]中使用soft-max将搜索空间改变为差分，这使得能够使用梯度下降而不是RL。

### 优化器的基本技术

优化问题，简言之就是在自变量定义域中选择一个较优自变量使得因变量最优。
![](/img/post/20181207/10.png)

**这里有三个重要问题：**
- 优化器可以运行什么样的搜索空间？
- 它需要什么样的反馈？
- 在找到一个好的配置之前需要生成/更新多少配置？

前两个问题决定了哪种类型的技术可用于优化器，最后一个问题阐明了技术的效率。虽然效率也是AutoML的一大追求（参见备注2.1），但我们并未根据它对现有技术进行分类。

基于前两个问题有两种简单搜索方法：`样本优化`、`梯度下降`。 表6列出了这些技术之间的简要对比：
![](/img/post/20181207/11.png)

#### 简单搜索方法

- `网格搜索`必须枚举搜索空间中的每个可能的配置。因此，当搜索空间连续时，离散化是必要的。 
- `随机搜索`[42]可以更好地探索搜索空间，因为将评估更多的位置。

![](/img/post/20181207/12.png)

#### 基于样本的优化

基于样本的优化[77]是一种更智能的搜索方法，与简单搜索方法相比，它会根据以前的配置迭代生成新配置。 

根据不同的优化策略，我们将现有方法分为三类，即`启发式搜索`，`基于模型的无导数优化`和`强化学习`。

**1、启发式搜索**

启发式搜索方法通常受到生物行为和现象的启发。
![](/img/post/20181207/13.png)

- `粒子群优化（PSO）`[48]：PSO受到鸟类植绒或鱼类学校教育的社会行为的启发。 它通过`搜索最佳样本周围的局部区域`进行优化。 PSO本身具有很少的超参数，并且易于并行化。
- `进化算法`[78]：进化算法受到生物进化的启发。`突变和选择`是主要组成部分。 一些最先进的方法，如CMA-ES[79]，用于解决各种复杂的优化问题。

> 上述方法已应用于AutoML（例如，[45]，[48]，[80]，[81]，[82]，[83]，[84]），

**2、基于模型的无导数优化**

基于访问样本构建模型，这有助于生成更有前途的新样本。
![](/img/post/20181207/14.png)

- `贝叶斯优化`[85][86]：贝叶斯优化通过高斯过程或其他模型（例如决策树[87]，随机森林[88]）在搜索空间上建立概率代理函数。然后，它通过优化基于代理函数的采集特征来选择下一个样本。由于在昂贵的优化方面具有出色的性能，`贝叶斯优化在AutoML中得到了广泛的应用。`
- `基于分类的优化`[39][89]：基于先前的样本，基于分类的优化模型通过学习分类器来搜索空间。通过分类，搜索空间分为正面和负面区域。然后，在阳性区域上生成新样本，从中可以获得更好的样本。模型方法简单有效。因此，基于分类的优化具有高效率和良好的可扩展性。
- `同步乐观优化`（Simultaneous Optimistic Optimization, `SOO`）[90]：SOO应用树结构来平衡搜索空间的探索和开发。当目标函数是局部Lipschitz连续时，SOO可以得到全局最优。但它也遭受了维度的诅咒，因为当目标函数的维数很高时，树的生长会变得极其艰难。

**3、强化学习**

强化学习（RL）[19]是一个非常通用和强大的优化框架，可以解决延迟反馈的问题。 
![](/img/post/20181207/15.png)

> RL已广泛用于NAS（[7]，[13]，[20]，[21]，[91]，[92]）。 

（这里准确来说是DRL）优点是CNN可以逐层构建，并且一层的设计可以看作是生成器给出的一个动作。 因此，迭代架构生成自然遵循RL的属性。

然而，再次由于反馈延迟，具有强化学习的AutoML消耗很大，需要探索更有效的方法。

#### 梯度下降

因为AutoML的优化问题非常复杂，这可能`不是可区分的`，甚至也`不是连续的`。因此，梯度下降很难成为有效的优化器。然而，关注一些`可微分损失函数`[93]，例如`平方损失`和`逻辑损失`，可以通过梯度下降来优化连续超参数。

与传统的优化问题不同，传统优化问题的梯度可以从目标中明确得出，这里需要`隐式计算梯度`。
- 通常，这可以通过`有限区分`来完成[93]。
- 另一种计算精确梯度的方法是通过`可逆学习`[36]，[43]，[94]。它已应用于深度学习超参数搜索。对于传统的机器学习，提出了`近似梯度`来搜索连续超参数[95]。通过这种不精确的梯度，可以在模型参数收敛之前更新超参数。

### 评估器的基本技术

**这里有一些重要问题：**
- 该技术能否提供快速评估？
- 该技术能否提供准确的评估？
- 评估器需要提供什么样的反馈？

网格搜索和随机搜索无需向优化器提供反馈，每个配置都是独立运行的。 但是，对于梯度下降方法，我们不仅需要在验证集上报告所获得的性能，还需要报告梯度w.r.t.，还必须计算当前配置。

**1、直接评估（Direct evaluation）：**
- 这是`最简单`的方法，通过直接训练训练集上的参数获得参数，然后在验证集上测量性能
- 它是`最昂贵`的方法，但也提供最准确的评估

**2、子采样（Sub-sampling）：**
- 由于训练时间在很大程度上取决于训练数据的数量，因此更快速地进行评估的直观方法是使用训练数据的子集训练参数
- 这可以通过使用`样本子集`或`特征子集`来完成

**3、提前停止（Early stop）：**
- 对于一些不良配置，即使有足够的训练时间，他们的表现也不会变得更好
- 根据经验，这些配置通常可以通过他们在训练开始时在验证集上的表现来轻松识别[60]，[88]，[96]。在这种情况下，我们可以提前终止训练，让评估员提供`不良反馈`

**4、参数重用（Parameter reusing）：**
- 使用从先前配置的评估中获得的参数来热启动需要针对当前评估进行训练的参数。
- 直观地，类似配置的参数可以彼此接近。因此，当前一个和当前一个之间的配置变化不大时，该技术可能是有用的。

**5、代理评估器（Surrogate evaluator）：**
- 对于可以轻松量化的配置，降低评估成本的一种简单方法是`建立一个预测给定配置性能的模型，具有过去评估的经验`[38]，[54]，[ 96]，[97]。
	- 这些模型作为代理评估器，可以省去计算上昂贵的模型训练，并显着加速AutoML。
	- 代理评估器也是一种加速评估准确性以提高效率的方法，它可用于预测运行时间，参数和预测学习工具的性能。
- 对于除超参数之外的配置，替代模型的使用相对受限，因为它们难以量化。在下节中，我们将介绍有望解决这一问题的`元学习`技术。

> 此处的代理评估程序将确定给定配置的实际性能，并为优化程序提供反馈以供后续更新。

> 由于简单性和可靠性，直接评估可能是评估器最常用的基本技术。 子采样，早期停止和参数重用增强了各种方向的直接评估，它们可以组合在一起，以便更快，更准确地进行评估。 但是，这三种技术的影响取决于AutoML问题和数据，很难断定他们可以在直接评估时改进哪些内容。


### 元学习

`元学习`：提取有关学习的元知识，训练元学习器来指导学习。

#### 一般元学习框架
![](/img/post/20181207/16.png)

首先，学习问题和工具的特点。这些特征（例如，数据集的统计特性，学习工具的超参数）通常被称为元特征，如[23]，[24]，[98]中详细描述的那样。

然后，从过去的经历中提取元知识。除了元特征之外，还需要有关元学习目标的经验知识，例如学习工具的性能和针对特定问题的有前途的工具。

之后，使用元知识训练元学习器。大多数现有的机器学习技术以及简单的统计方法可以用于生成元学习器。训练有素的元学习器可以应用于即将出现的特征性学习问题，以预测兴趣（make predictions of interest）。

表7总结了根据文献中的现有工作应该为不同目的提取和训练的元知识和元学习器。
![](/img/post/20181207/17.png)
![](/img/post/20181207/18.png)

#### 配置评估（评估器）

由于模型训练和验证的成本，AutoML中计算密集度最高的步骤是配置评估。 元学习器可以作为代理评估员进行训练，以预测性能，适用性或配置排名。 

我们总结了元学习在配置评估中的代表性应用如下：

`（1）模型评估`：任务是在给定学习问题的情况下，通常由数据集指定，学习算法`是否适用或如何适用`，或`候选算法的排名`，以便最合适和最有希望的算法可以是选择。

> `元知识`包括学习问题的元特征和不同模型的经验表现，以及模型的元特征。

> 元学习器被训练以将元特征映射到性能[50]，[99]，[100]，适用性[101]，[102]或候选算法排名[103]，[104]，[105]， [106]模型。最近关于该主题的研究包括主动测试[？]，[107]，运行时预测[52]，[108]以及更复杂的模型测量[109]，[110]。有关该主题的更完整的评论可以在[98]中找到。

`（2）一般配置评估`：简而言之，为了加速配置评估，元学习器需要接受训练，以预测配置的性能或适用性。 
- 当在配置生成过程中使用时，这样的元学习器可以显着减少实际模型训练的数量。
- 在配置选择设置中，其中列举了所有可能的选择，可以根据元学习器预测的分数和排名直接选择最佳配置。

> 对其他类型配置的评估可以以类似的方式配备元学习：在ExploreKit[9]中，对排名分类器进行训练以对候选特征进行排名。在[111]中，meta-regressor经过训练，可以将内核宽度评估为支持向量机的超参数

#### 配置生成（优化器）

元学习还可以通过学习来促进配置生成，例如，用于特定学习任务的配置，用于生成或选择配置的策略，或者精炼的搜索空间。 通常，这些方法可以提高AutoML的效率：

`（1）有希望的配置生成`：目的是直接为给定的学习问题生成性能良好的配置。 

> 为此，提取了指示经验上良好配置的元知识，并且元学习器将学习问题的特征作为输入并预测有前景的配置，例如内核[112]，自适应网络架构[113]，[114]。

`（2）热启动配置生成`：利用有前途的配置生成中使用的元知识来更好地初始化配置搜索。在给定新的学习任务的基础上，基本方法是在元特征空间中找到与其最接近的过去任务，并使用其最佳性能配置来初始化搜索。 

> 大多数这类工作都集中在超参数调整，粒子群优化[115]，[116]，进化算法[117]和基于序列模型的优化[5]，[118]，[119]。

`（3）搜索空间优化`：元学习可以通过优化搜索空间来加速配置搜索。

> 该系列的现有工作努力评估配置的重要性[120]，[121]，或识别搜索空间中的有希望的区域[122]。

#### 动态配置自适应

到目前为止，我们一直关注不同学习问题和工具之间的差异，这提出了AutoML的需求。然而，在现实生活中，即使在单个数据集中，数据分布也会变化，尤其是在数据流中。数据分布的这种变化通常被称为`“概念漂移”`。 

在经典的机器学习实践中，概念漂移通常先于假设或后检测，然后进行特定设计，以便学习工具能够适应这种漂移。元学习可以通过检测概念漂移并动态调整学习工具来帮助自动执行此过程：

`（1）概念漂移检测`：通过统计数据或属性，我们可以检测学习问题中是否存在概念漂移。 

> 在[123]中，基于元学习识别可能提供表示概念变化的上下文线索的属性。在[124]中，提出了一种非参数方法来检测概念漂移。 设计了一类新的距离测量来指示数据分布的变化，并通过监视数据流中的分布变化来检测概念漂移。

`（2）动态配置自适应`：一旦检测到概念漂移，就可以通过预测数据当前部分的有希望的配置来执行配置自适应[125]，[126]，[127]。 这些方法类似于有希望的配置生成方法。


### 迁移学习

`迁移学习`：其中可转移的知识来自过去的经验，以帮助即将到来的学习实践。

#### 一般迁移学习框架

![](/img/post/20181207/19.png)

根据[26]中的定义，迁移学习通过使用来自源域和学习任务的知识，尝试改进对目标域和学习任务的学习。 

迄今为止在AutoML中利用的可转移知识包括但不限于：1）学习模型或其参数; 2）学习工具的配置; 3）寻找有前途的学习工具的策略。

#### 配置生成（优化器）

`（1）代理模型转移`：超参数的基于序列模型的优化（SMBO）受冷启动问题的影响，因为从头开始为每个AutoML问题初始化代理模型的成本很高。
- 因此，提出了迁移学习技术，通过转移代理模型[128]或其组件（如核函数[129]）来重用从过去经验中获得的知识。

`（2）网络块传输`：由于网络的可转移性，传输学习尤其广泛用于网络架构搜索领域。
- 在[21]，[59]中，NAS问题被转换为搜索体系结构构建块。可以在小数据集上以低成本学习这些块并将其转移到较大的数据集。

应当注意，多任务学习（与迁移学习密切相关的主题）也用于帮助配置生成。
- 在[130]中，贝叶斯优化伴随着多任务高斯过程模型，以便从过去的调整任务中获得的知识可以转移到热启动搜索。
- 在[131]中，训练多任务神经AutoML控制器以学习神经网络的超参数。

#### 配置评估（评估器）

在寻找有前途的学习工具时，需要评估大量的候选配置。在通常的方法中，这种评估涉及昂贵的模型训练。

**通过从先前的配置评估中转移知识，我们可以从头开始避免为即将进行的评估训练模型，并显着提高效率。**

基于众所周知且经过验证的神经网络可转移性，传递学习技术已被广泛应用于NAS方法中，以加速候选架构的评估：

`（1）模型参数传递`：最直接的方法是从训练有素的架构中传输参数以初始化新的参数。

> 根据[74]，初始化具有转移特征层的网络，然后进行微调，可以改善深层神经网络的性能。

> 根据这一想法，在[92]中，儿童网络被迫分担权重，以便显着降低训练成本。

`（2）特征保留转换`：事实证明，这种方法能够显着加速新网络的训练。

> 另一个关注特征保留转换的研究重点，首先在Net2Net [132]中提出，其中新网络被初始化以表示给定训练模型的相同特征。

> 此外，在最近的方法中，保持特征的转换也激发了探索网络架构空间的新策略[62]，[72]。

### 应用

#### 使用Auto-sklearn选择模型

由于每个学习问题都有自己对学习工具的偏好[1]，当我们处理一个新的分类问题时，自然会尝试一组分类器，然后从它们的集合中得到最终的预测。 

以Scikit-Learn [11]为例，表4列出了一些常用的分类器及其超参数。在[5]，[34]中，上述问题被认为是CASH问题（例1）。集合结构转移到`公式（2）`，这是一个优化问题，**最小化验证集的损失并涉及参数和超参数**。
![](/img/post/20181207/20.png)

> 此公式标记为公式（2），下面简记为（2）

因此，此处的配置由Scikit-Learn中的分类器选项及其超参数组成，搜索空间由此类配置跨越。但是，（2）很难优化。首先，目标函数在验证集上定义，我们几乎没有关于此目标的信息。然后，需要对变量进行优化，即θ和F<sub>j</sub>甚至不连续，例如，对于kNN，θ包括最近邻居的数量。 最后，为了获得有关验证集的信息，我们需要训练模型F<sub>j</sub>并更新其参数w<sub>j</sub>，这通常非常昂贵。

在[34]中，基于序列模型的算法配置（SMAC）[88]，一种贝叶斯优化方法，被用作求解的优化器（2）。然后，使用基本方法，即直接评估作为评估器。最后，元学习被用作先进技术，这有助于更好地初始化（即前面提到的热启动）。

#### NAS中的强化学习

自AlexNet成功应对ImageNet数据集[14]的图像分类以来，神经架构设计的变化一直是获得更好预测性能的重点。 因此，一个非常自然的问题是：我们能否自动设计神经架构，以便生成的架构可以在各种任务和数据集中具有良好的学习性能[7]，[12]，[13]。

以在循环神经网络（CNN）中生成卷积层为例。对于每个卷积层，基本上，我们需要确定（a）过滤器的数量，（b）过滤器高度，（c）滤波器宽度，（d）步幅高度，（e）步幅宽度和（f）跳过连接（即，应将先前层的哪个输出作为当前层的输入）。

这些设计的图示在图10中。一旦确定了这些配置，就需要在训练数据上训练网络，然后基于从验证集获得的性能来调整超参数。设计选择和超参数是配置。

表10：表1中的示例结合图6中的建议框架。“naive”意味着评估器没有特殊设计，评估是通过优化学习工具对训练数据的参数来直接完成的。
![](/img/post/20181207/21.png)

然而，**CNN自然地以增量方式构建，即数据首先由低级处理，然后提出更高级别。**因此，与前面的示例不同，CNN中的参数和超参数的数量是未知的，因为层数不固定。

如图18所示，这些激励表示CNN的体系结构作为顺序数据，并学习循环神经网络（RNN）。

此外，由于搜索空间可以逐步建立，可以捕获这种动态属性的强化学习用于训练RNN [7]，[13]。 RNN充当优化器，直接评估用作评估器。

最后，由于RL收敛缓慢，为了加快搜索速度，后来在[21]，[59]中开发了用于将搜索空间切割成几个块的迁移学习。
![](/img/post/20181207/22.png)

#### 使用ExploreKit构建特征

自动特征构建领域最具代表性的作品之一是ExploreKit [9]。 它旨在生成新特征，以便可以提高后续学习工具的性能。 图19显示了ExploreKit的系统架构。 这里的配置是一组生成的特征。
![](/img/post/20181207/23.png)

主体是迭代过程，其中每个迭代包括三个步骤，以搜索这样的配置空间：`候选特征生成`，`候选特征排序`，`候选特征评估和选择`。 

此外，在排名步骤中使用元学习技术来快速估计候选特征的有用性并加速后续评估步骤。

在候选要素生成步骤中，通过对已经选择的要素应用运算符来构造新要素。所用的运算符包括：
- 一元的（例如，离散化，归一化）
- 二进制的（例如，+， - ，×，÷）
- 高阶的（例如，GroupByThenMax，GroupByThenAvg）

调用预定的枚举过程以在适用于生成候选的所有选定特征上应用这些运算符。为了限制候选特征集的大小，生成的特征将不再被重用以进一步生成新的候选者。

由于ExploreKit会详尽地生成候选项，因此评估所有这些特征可能是计算上可行的。为解决此问题，ExploreKit在评估和选择步骤之前设置了排名步骤。在此步骤中，使用具有特征工程的历史知识训练的排名分类器来快速对候选特征进行排名。在随后的评估步骤中，将首先考虑预测更有用的特征。

### 总结

虽然最近在[34]中提到了AutoML，并且在ICML-2014的AutoML研讨会[134]中引入，如引言（第1节）中所述，这种想法很久以前就出现了。 然而，由于大数据，现代计算机的计算量增加，当然还有对机器学习应用的巨大需求，自动化最近才成为可能并且成为一个重点。 图1显示了AutoML的一个大图，其所有组件，即特征工程，模型选择和算法选择，都被机器学习，数据挖掘和人工智能领域的许多研究人员单独触及。

在`特征级别`上，特征选择是机器学习中的传统主题，它可以自动删除不必要的特征，使学习模型更简单，更易于理解[135]。 提出了许多方法，Lasso [136]是它们的里程碑。 降维方法，如主成分分析（PCA）[64]和线性判别分析（LDA）[65]，也被广泛用于处理高维特征。 这些方法试图找到输入要素的更好表示。 然而，尺寸减小的尺寸需要人的规格。 在20世纪90年代，许多尝试基于遗传算法自动构建更好的特征[67]，[137]，[138]。 但是，最近自动学习特征表示对于某些结构化数据变得可能，例如用于图像的卷积神经网络（CNN）和用于（RNN）顺序数据的递归神经网络[63]。

`模型选择`是从给定数据的一组候选模型中选择适当模型的任务。理论基础，即统计学习理论[139]，[140]，首先为模型选择铺平道路，它显示了模型如何从给定数据推广到看不见的数据。对于特定模型，其性能受其超参数的影响最大。网格搜索是确定超参数的适当值的最常用方法。但是，它只能处理极少数的超参数。后来，基于优化的方法，例如无导数优化[141]，[142]和基于梯度的优化[93]，已被考虑用于寻找超参数。这些方法对优化模型有很强的假设，并且不考虑学习问题中的随机性。这些激发了许多量身定制的方法来选择各种机器学习模型，例如SVM的内核选择[143]，K-means的学习K [144]和神经网络架构的遗传编程[80]，[82] 。最后，由于单个模型可能不够强大，因此在[145]中考虑了模型的集合。

最后，一旦模型完成，需要`优化算法`来找到好的参数。算法选择最初可以追溯到1970年代，许多研究人员试图为硬组合问题设计更好的算法[51]，[146]。由于这些问题大多是NP难的，因此无法找到最佳解决方案。每种算法都有自己的启发式和强度来解决某类问题。算法选择尝试识别给定组合问题的最佳算法。传统上，在机器学习中使用凸和简单模型，例如逻辑回归和SVM。此外，数据集也不大。在这样的环境下，算法选择不是一个重要的问题，很容易找到给定模型的好参数[147]。最近，随着数据变得越来越大，复杂模型越来越流行，通常无法找到好的参数，优化算法会对泛化性能产生重要影响[71]，[148]，[149]。

如今，AutoML是一个非常复杂和活跃的研究领域，AutoML中存在许多新的机会和问题，这些机会和问题在上述历史中并未被强化，例如，使用高级技术。 许多专注于AutoML的论文出现在各种会议和期刊上，如ICML，NIPS，KDD，AAAI，IJCAI和JMLR; 组织了许多研讨会，例如2014年至2018年ICML的AutoML研讨会[134]，[150]，[151]，[152]，[153]; 还有一些比赛，例如PAKDD [154]和NIPS [155]的AutoML Chal  -  lenge也是如此。

`基本技术`：在文章起始我们提出了一个框架，其中配置基于优化器和评估器之间的交替迭代进行更新。 但是，当数据集较大时，仅在评估器识别参数后才更有效地更新配置。 最近在[161]中探索了这种想法，用于在深度网络中找到连续的超参数。 未来的一个方向是同时更新两个参数（由评估器控制）和配置（由优化器控制）。

`高级技术`：`元学习`已被广泛用于促进AutoML。然而，对于使用元学习有一些考虑，这也表明了未来研究的方向，例如：如何更好地表征学习问题，工具和任何其他感兴趣的经验;如何有效地收集元知识;以及如何研究学习工具成功或失败的原因。此外，我们想指出虽然元学习可以帮助AutoML，但如何自动化元学习也是一个有趣且有意义的研究课题。

`迁移学习`主要应用于网络架构搜索领域。我们期待在更广泛的AutoML范围内采用更多的迁移学习技术，特别是那些解决小数据问题的技术，这迄今阻碍了机器学习在许多重要且有意义的业务（例如医疗）中的应用。而且，已经很好地认识到知识转移并不总是提供改进。迁移学习的一个主题是“负迁移”[26]，其中研究了知识转移导致性能退化的现象。解决此问题的一个有吸引力的解决方案是自动确定何时以及如何转移哪些知识。








